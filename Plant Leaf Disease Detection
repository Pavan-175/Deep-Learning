#IMPORTING ALL THE REQUIRED LIBRARIES AND API
import pandas as pd
import numpy as np
import keras
import tensorflow as tf
from keras.models import Sequential
from tensorflow import keras
from tensorflow.keras import layers
from keras.layers import Dropout
from keras.layers import Dense
import matplotlib.pyplot as plt

tf.test.gpu_device_name()

data_dir_path = "/content/PlantVillage"

#PREPROCESSING THE DATASET
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir_path,
    shuffle=True,
    seed=123,
    validation_split=0.70,
    subset="training",
    image_size=(256,256),
    batch_size=32,
)

class_names = dataset.class_names
class_names

#PARTITIONING THE GIVEN DATASET
def get_dataset_partition_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):
    
    ds_size = len(ds)
    
    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=12)
    train_size = int(ds_size * train_split)
    val_size = int(ds_size * val_split)

    
    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)
    
    return train_ds, test_ds, val_ds
train_ds, test_ds, val_ds = get_dataset_partition_tf(dataset)

AUTOTUNE = tf.data.experimental.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

resize_and_rescale = tf.keras.Sequential([

    layers.experimental.preprocessing.Resizing(256,256),
    layers.experimental.preprocessing.Rescaling(1.0/255)

])

#CREATING VGG16 MODEL
model = Sequential([

    resize_and_rescale,

    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,256,256,3)),

    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3,3), activation='relu'),

    layers.MaxPooling2D((2, 2)),

    

    layers.Conv2D(64, (3,3), activation='relu'),

    layers.MaxPooling2D((2, 2)),

    

    layers.Conv2D(64, (3,3), activation='relu'),

    layers.MaxPooling2D((2, 2)),

    

    layers.Conv2D(128, (3,3), activation='relu'),

    layers.MaxPooling2D((2, 2)),

    

    layers.Conv2D(128, (3,3), activation='relu'),

    layers.MaxPooling2D((2, 2)),

    

    layers.Flatten(),

    layers.Dense(256, activation='relu'),

    layers.Dense(15, activation='softmax')

])

#COMPILING THE CREATED MODEL
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
no_of_epochs=30
history=model.fit(train_ds,validation_data=val_ds,epochs=no_of_epochs,batch_size=32)

#VISUALISATION OF DIFFERENCE BETWEEN TRAINING AND VALIDATION 
#ACCURACIES AND LOSS GRAPHS
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(no_of_epochs)

plt.figure(figsize=(10,8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
scores = model.evaluate(test_ds)
scores

#MAKING PREDICTION ON CREATED MODEL
def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())
    img_array = tf.expand_dims(img_array, 0)
    
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    
    return predicted_class, confidence
plt.figure(figsize=(15, 15))
tak = test_ds.take(3)
for images, labels in tak:
    for i in range(9):
        ax = plt.subplot(3, 3, i+1)

        plt.imshow(images[i].numpy().astype("uint8"))
        image_1 = images[i].numpy()
        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = class_names[labels[i]]
        
        plt.title(f"Actual: {actual_class}, \n Predicted: {predicted_class}, \n Confidence: {confidence}")        
        plt.axis("off")


#TESTING WITH THE REAL PLANT IMAGES TAKEN FROM CAMERA
img = tf.keras.utils.load_img(

'/content/drive/MyDrive/Leaf unresized/IMG_20220317_082436.jpg', target_size=(256,256)

)

img_array = tf.keras.utils.img_to_array(img)

img_array = tf.expand_dims(img_array, 0)

predictions = model.predict(img_array)

score = tf.nn.softmax(predictions[0])

print(

    "This image most likely belongs to {}."

    .format(class_names[np.argmax(score)], 100 * np.max(score))

)
